name: Performance Monitoring

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 6 * * *'  # Daily at 6 AM UTC
  workflow_dispatch:

env:
  NODE_VERSION: '20.x'

jobs:
  # Bundle size analysis
  bundle-analysis:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Build for production
      run: npm run build

    - name: Analyze bundle size
      run: |
        # Vite builds to dist/, not build/
        # Create simple bundle size report since vite-plugin-visualizer requires dev server
        if [ -d dist/assets ]; then
          find dist/assets -name "*.js" -type f -exec sh -c 'echo "$(wc -c < "$1") bytes: $1" >> bundle-report.txt' _ {} \;
          echo "‚úÖ Bundle analysis completed" >> bundle-report.txt
        else
          echo "‚ö†Ô∏è No dist/assets directory found" > bundle-report.txt
        fi

    - name: Bundle size check
      run: |
        # Check if bundle size exceeds threshold
        if [ ! -d dist ]; then
          echo "‚ùå Build directory not found"
          exit 1
        fi

        BUNDLE_SIZE=$(find dist -name "*.js" -type f -exec cat {} \; | wc -c)
        THRESHOLD=1048576  # 1MB threshold

        echo "Bundle size: $BUNDLE_SIZE bytes (threshold: $THRESHOLD bytes)"

        if [ $BUNDLE_SIZE -gt $THRESHOLD ]; then
          echo "‚ùå Bundle size exceeds threshold"
          echo "Consider code splitting, tree shaking, or removing unused dependencies"
          exit 1
        fi

        echo "‚úÖ Bundle size is within acceptable limits"

    - name: Upload bundle report
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: bundle-analysis
        path: bundle-report.txt

  # Lighthouse CI
  lighthouse-ci:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Build application
      run: npm run build

    - name: Serve application
      run: |
        npx serve -s dist -l 3000 &
        sleep 10  # Wait for server to start

    - name: Run Lighthouse CI
      run: |
        npx @lhci/cli@latest autorun
      env:
        LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}

    - name: Upload Lighthouse reports
      uses: actions/upload-artifact@v4
      with:
        name: lighthouse-reports
        path: .lighthouseci/

  # Performance regression testing
  performance-regression:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'

    steps:
    - name: Checkout PR branch
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Build PR version
      run: npm run build

    - name: Measure PR performance
      run: |
        # Add your performance measurement script here
        echo "Measuring PR performance..."
        # Example: Run performance tests and save results
        npm run test:performance -- --outputFile=pr-performance.json

    - name: Checkout main branch
      uses: actions/checkout@v4
      with:
        ref: main
        clean: false

    - name: Build main version
      run: |
        npm ci
        npm run build

    - name: Measure main performance
      run: |
        echo "Measuring main branch performance..."
        npm run test:performance -- --outputFile=main-performance.json

    - name: Compare performance
      run: |
        # Add performance comparison logic here
        echo "Comparing performance between main and PR..."

        # Example comparison (implement based on your metrics)
        PR_SCORE=$(cat pr-performance.json | jq '.score')
        MAIN_SCORE=$(cat main-performance.json | jq '.score')

        REGRESSION_THRESHOLD=5  # 5% regression threshold

        if [ "$PR_SCORE" -lt "$MAIN_SCORE" ]; then
          REGRESSION=$(echo "scale=2; ($MAIN_SCORE - $PR_SCORE) / $MAIN_SCORE * 100" | bc)

          if (( $(echo "$REGRESSION > $REGRESSION_THRESHOLD" | bc -l) )); then
            echo "‚ùå Performance regression detected: ${REGRESSION}%"
            exit 1
          fi
        fi

        echo "‚úÖ No significant performance regression detected"

  # Core Web Vitals monitoring
  web-vitals:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'

    - name: Install dependencies
      run: npm ci

    - name: Build application
      run: npm run build

    - name: Start application
      run: |
        npx serve -s dist -l 3000 &
        APP_PID=$!
        echo "APP_PID=$APP_PID" >> $GITHUB_ENV
        sleep 10

    - name: Measure Core Web Vitals
      run: |
        # Use Lighthouse JSON to extract Web Vitals metrics
        npx @lhci/cli@latest collect --url http://localhost:3000 --outputDir=.lighthouseci-vitals || true

        # If Lighthouse collection failed, create a minimal report
        if [ ! -f .lighthouseci-vitals/lhr-*.json ]; then
          echo "‚ö†Ô∏è Could not collect Lighthouse metrics, creating fallback report"
          echo '{"metrics": {"LCP": 0, "FID": 0, "CLS": 0}}' > web-vitals.json
        else
          # Extract metrics from Lighthouse JSON
          LHR_FILE=$(ls .lighthouseci-vitals/lhr-*.json | head -1)
          if [ -f "$LHR_FILE" ]; then
            jq '{LCP: .audits."largest-contentful-paint".numericValue, FID: .audits."max-potential-fid".numericValue, CLS: .audits."cumulative-layout-shift".numericValue}' "$LHR_FILE" > web-vitals.json || echo '{}' > web-vitals.json
          fi
        fi

    - name: Validate Web Vitals thresholds
      run: |
        if [ ! -f web-vitals.json ]; then
          echo "‚ö†Ô∏è Web Vitals report not available, skipping validation"
          exit 0
        fi

        LCP=$(jq -r '.LCP // 0' web-vitals.json)
        CLS=$(jq -r '.CLS // 0' web-vitals.json)

        echo "Core Web Vitals:"
        echo "- LCP: ${LCP}ms (threshold: <2500ms)"
        echo "- CLS: ${CLS} (threshold: <0.1)"

        # Warn if metrics are available but outside thresholds
        if [ "$LCP" != "0" ] && [ "$LCP" != "null" ]; then
          if (( $(echo "$LCP > 2500" | bc -l) )); then
            echo "‚ö†Ô∏è LCP above threshold"
          fi
        fi

        if [ "$CLS" != "0" ] && [ "$CLS" != "null" ]; then
          if (( $(echo "$CLS > 0.1" | bc -l) )); then
            echo "‚ö†Ô∏è CLS above threshold"
          fi
        fi

        echo "‚úÖ Web Vitals measurement completed"

    - name: Stop application
      run: kill $APP_PID

    - name: Upload Web Vitals report
      uses: actions/upload-artifact@v4
      with:
        name: web-vitals-report
        path: web-vitals.json

  # Generate performance report
  performance-report:
    runs-on: ubuntu-latest
    needs: [bundle-analysis, lighthouse-ci, web-vitals]
    if: always()

    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v6

    - name: Generate performance summary
      run: |
        echo "# Performance Report - $(date)" > performance-report.md
        echo "" >> performance-report.md

        echo "## Bundle Analysis" >> performance-report.md
        if [ -d bundle-analysis ]; then
          echo "‚úÖ Bundle analysis completed" >> performance-report.md
        else
          echo "‚ùå Bundle analysis failed" >> performance-report.md
        fi
        echo "" >> performance-report.md

        echo "## Lighthouse Scores" >> performance-report.md
        if [ -d lighthouse-reports ]; then
          echo "‚úÖ Lighthouse audit completed" >> performance-report.md
        else
          echo "‚ùå Lighthouse audit failed" >> performance-report.md
        fi
        echo "" >> performance-report.md

        echo "## Core Web Vitals" >> performance-report.md
        if [ -f web-vitals-report/web-vitals.json ]; then
          echo "‚úÖ Core Web Vitals measured" >> performance-report.md
          cat web-vitals-report/web-vitals.json | jq -r 'to_entries[] | "- \(.key): \(.value)"' >> performance-report.md
        else
          echo "‚ùå Core Web Vitals measurement failed" >> performance-report.md
        fi
        echo "" >> performance-report.md

        echo "## Recommendations" >> performance-report.md
        echo "- Monitor bundle size regularly" >> performance-report.md
        echo "- Optimize images and assets" >> performance-report.md
        echo "- Implement code splitting" >> performance-report.md
        echo "- Use performance budgets" >> performance-report.md

    - name: Upload performance report
      uses: actions/upload-artifact@v4
      with:
        name: performance-report
        path: performance-report.md

    - name: Comment performance summary on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const fs = require('fs');

          let performanceComment = `## üìä Performance Report

          Performance analysis has been completed for this PR.

          ### Results Summary
          `;

          // Add bundle analysis results
          if (fs.existsSync('bundle-analysis')) {
            performanceComment += '‚úÖ Bundle analysis: Passed\n';
          } else {
            performanceComment += '‚ùå Bundle analysis: Failed\n';
          }

          // Add Lighthouse results
          if (fs.existsSync('lighthouse-reports')) {
            performanceComment += '‚úÖ Lighthouse audit: Completed\n';
          } else {
            performanceComment += '‚ùå Lighthouse audit: Failed\n';
          }

          // Add Web Vitals results
          if (fs.existsSync('web-vitals-report/web-vitals.json')) {
            performanceComment += '‚úÖ Core Web Vitals: Measured\n';
          } else {
            performanceComment += '‚ùå Core Web Vitals: Failed\n';
          }

          performanceComment += `

          ### Detailed Reports
          Check the workflow artifacts for detailed performance analysis.

          ---
          *Performance monitoring powered by GitHub Actions*
          `;

          try {
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: performanceComment
            });
          } catch (error) {
            console.log('Note: Could not post PR comment, but performance report is available in artifacts');
            console.log(`Error: ${error.message}`);
          }